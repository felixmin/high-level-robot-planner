---
notion-id: 2c420c92-0436-80c6-90e4-c53f8d6b078e
---
# Intro

> [!note]+ Notes
> “note that the decoder only exists to give the LAM training signal” - genie

> [!note]+ models perform great if they have a detailed plan - shown in mimic-video
> they compare a policy conditioned on video model outputs vs conditioned on the ground truth video

> [!note]+ VLAs vs Flow Matching
> [https://www.notion.so/Master-Thesis-Learning-vision-based-long-horizon-robot-manipulation-policies-28720c920436802a9da5edad6510dc31?source=copy_link#2e420c920436808899e2d897cac788f5](https://www.notion.so/Master-Thesis-Learning-vision-based-long-horizon-robot-manipulation-policies-28720c920436802a9da5edad6510dc31#2e420c920436808899e2d897cac788f5)

# Related Work

> [!note]+ Notes
> > [!note]+ General LAM approaches to unsupervised LAM from video
> > as in What Do Latent Action Models Actually Learn?

# Method

> [!note]+ Notes
> Motivate the analysis of the latents with use-cases introduced earlier
> 
> “note that the decoder only exists to give the LAM training signal” - genie

# Results

> [!note]+ Notes
> litmus test: a quick test to expose underlying truth

# Conclusion

> [!note]+ Notes
