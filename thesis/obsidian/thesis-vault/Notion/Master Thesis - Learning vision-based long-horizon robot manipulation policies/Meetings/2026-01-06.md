---
notion-id: 2e220c92-0436-8003-93bf-c611353b886c
base: "[[Meetings.base]]"
Tags: []
Created: 2026-01-08T13:20:00
---
# Progress

- Good results with current setup and multiple datasets

- Similar results with 4 tokens of codebook size 8 vs 1 token of codebook size 4096
    - INTERESTING INSIGHT: it has VERY similar nr of unique token sequences

# Thoughts

- Maybe we have better interpretability with 1 token because the vector space is “better”
    - Maybe we have better interpretability with 1 token because the vector space is “better”
→ e.g. if we have 1 codebook vector for move a little to the right and 1 for move more to the right the codebooks vectors could be very similar… with 4 tokens this similarity is harder to express
→ we need to see this in downstream experiments
- Why does dino train loss go up?
    - Does aux loss influence network gradient updates?
→ New run without aux loss?

- “try to not loose focus from your main investigation / what you mainly want to show”
→ Am I drifting away too much?


# Next Steps

- Optical Flow
- Foundation policy implementation and training

- What does oliver think about the current state and next steps?

## Notes

- Check again if gradients dont propagate through
- is dino frozen??
- parameter count vergleichen
    - wie viele parameter hat dino vs pure pixel ??

- image encoder
- raw images, kein aux loss → nur peter abbeel
    - peter hat aux loss auf hand keypoints
    - welche input rep ist orth zu welche architektur verwendet man
        - pixels
        - optical flow
        - masks
        - etc
        - → andere machen nur neue architekturen
- wie viele daten braucht man um dann bei einem task sehr gut zu werden?


