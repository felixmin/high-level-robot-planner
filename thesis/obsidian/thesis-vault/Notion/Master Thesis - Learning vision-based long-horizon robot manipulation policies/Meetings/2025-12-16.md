---
notion-id: 2ca20c92-0436-80de-b32f-d4a100f3de2c
base: "[[Meetings.base]]"
Tags: []
Created: 2025-12-15T19:45:00
---
# Progress

1. Implemented language table from oxe
2. Added numerous evaluation plots to see what we are learning
3. Integrated dino to see potential improvements

> [!note]+ Generally good results on long run with LAPA
> Initial long run, no dino usage
> 
> Long run with DINO only in the encoder
> 
> - Good codebook usage
>     - Becomes more evenly distributed over time
> → The model learns to properly leverage all expressivity in the latent space
> - Correlation between relative motion and action tokens → great!
> - Correlation between absolute position and action token → discussed later
> - Latent transfer reconstruction is not working properly…
> → Strongly assuming that this is because the absolute initial position in the latent is the wrong if we transfer the latent to another image pair
> → Should we investigate this? I dont think so…

# Throughts

4. Is it an issue that we learn the absolute initial position of the moving entities (object / gripper)?
I think no because:
    - Argument 1:
Thinking from the other end…
We will have a VLM that predicts an action token that tells a certain effector how to move…
But what if we have multiple effectors (e.g. bimanual setup or background humans / robots)
Which entity are we talking about? 
→ We somehow need to point to the entity that we want to move… for that the initial position is valuable
→ This will lead to a bloated latent space where each action exists in combination with each initial position… but is this bad? Is there an alternative avoiding the issues above?
    - Argument 2:
The decoder doesnt have semantic understanding… it can recreate an image and move certain pixels, but it doesnt have an understanding of what the effector or the relevant object is…
→ If we provide the decoder only a relative movement, which object is moved? The decoder doesnt know…

5. How to use DINOv3 optimally? Ablate later?
    - I am already running 3 runs to compare effects of DINO (if gamechanger or not)
    - Keep it at that for now and continue with something that works… we can add it for last improvements later again

6. When should you begin with “serious” runs? Now I still am changing many parameters… do you run the experiments of which the numbers will be on the paper only at the end or should you keep the numbers already early on? Is this even possible?
    - Experiment and develop a feeling now
    - Run serious runs later
→ because architecture, configs etc will change… highly improbable that we can use current numbers

7. Which benchmark will we choose later? We should run on current benchmarks for comparison, not only lego
8. 

# Next steps

- Run experiments that i did with language table on bridge or a combination
- Integrate raft with on the fly motion tracking
- Go back to cluster for that (probably not enough VRAM locally)
- Refine cluster setup to run experiments and sweeps easily


9. How do we collaborate? What do we expect from a collaboration?

# Draft

Dear Dr. Mees,

My name is Felix Minzenmay, and I am a Master’s student at the Technical University of Munich in Prof. Angela Schöllig’s Learning Systems & Robotics Lab (supervised by Oliver Hausdörfer). I am reaching out because our current research direction is closely aligned with recent Microsoft work such as “IGOR: Image-GOal Representations” and “What Do Latent Action Models Actually Learn?”.

In our project on latent action learning from videos, we are exploring replacing purely pixel-space future reconstruction with motion supervision via** optical flow prediction**, aiming for a more action-relevant latent space. Our goal is to train a **goal-conditioned visuomotor policy** and validate it with **real-robot rollouts** on a **LEGO assembly** task. If this matches your interests, we’d be glad to discuss whether it makes sense to pursue this direction together, or to connect with the relevant IGOR authors.

Kind regards,

Felix Minzenmay
