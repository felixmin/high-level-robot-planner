# @package data.adapter

# Octo-like TFDS pipeline for multi-dataset GCS streaming:
# - Use TFDS `SkipDecoding()` for RLDS `steps`, so images are emitted as encoded
#   `tf.string` (cheap to shuffle/mix).
# - Mix + shuffle *before* decode/resize, then decode/resize after mixing.
#
# This targets the long-tail "cold switch" stalls we see with many datasets.

defaults:
  - oxe_tf_low_ram
  - _self_

tf:
  tfds_read:
    source: gcs
    skip_steps_decoding: true
    # Moderate parallelism for remote reads.
    cycle_length: 8
    decode_parallelism: 4
    interleave_parallelism: 4

  pipeline:
    # Decode+resize happens after mixing (see `post_mix_decode_resize`).
    post_mix_decode_resize: true
    emit_encoded_pairs: true
    # Some per-dataset concurrency to keep episodes flowing.
    episode_concurrency: 4
    transform_parallelism: 8
    interleave_parallelism: 4

  train:
    # Keep per-episode shuffles off for predictable startup; rely on post-mix shuffle.
    episode_queue_shuffle_buffer: 0
    intra_episode_sample_shuffle_buffer: 0
    # Shuffle encoded (string) pairs after mixing. This is much cheaper than
    # shuffling decoded uint8 images.
    global_stream_shuffle_buffer: 1024

  prefetch:
    # Small per-dataset buffer (per-sample) to reduce switch stalls.
    per_dataset_stream_buffer: 2
    # Batched prefetch after decode+resize.
    final_stream_buffer: 16

  mixing:
    mix_block_length: 1
    selector_run_length: 1
    strategy: sample
    parallelism_mode: sqrt
    python_prefetch_queue_size: 2
    python_prefetch_min_ready_datasets: 1
    python_prefetch_wait_timeout_s: 600
    per_dataset_private_threadpool_size: 0
