# @package data.adapter

# TensorFlow/TFDS OXE streaming adapter (tf.data).
# These parameters are ONLY used by the TF backend (not by training/model code).

tf:
  # Frame selection within each [t, t+offset] training sample.
  # Default "endpoints" preserves the current 2-frame output.
  pair_frames:
    mode: endpoints           # endpoints|all|stride|fixed_n
    stride: 1                 # used when mode=stride
    n: 2                      # used when mode=fixed_n

  # Debug/testing helpers (no network/TFDS required when enabled).
  debug:
    use_synthetic_data: false
    synthetic_num_samples: 10000

  # Keep tf.data iterator alive across epochs to avoid re-filling shuffle buffers.
  iterator:
    persistent: true

  # Episode -> pair sampling behaviour.
  sampling:
    samples_per_episode: 0   # 0 = yield all pairs in each episode
    seed: 42

  # Shuffle behaviour (train vs val).
  train:
    episode_queue_shuffle_buffer: 2000
    intra_episode_sample_shuffle_buffer: 100
    global_stream_shuffle_buffer: 5000

  val:
    episode_queue_shuffle_buffer: -1
    intra_episode_sample_shuffle_buffer: 64
    global_stream_shuffle_buffer: 2

  # Prefetch behaviour (memory/throughput trade-off).
  prefetch:
    final_stream_buffer: 32           # after mixing (per-batch)
    per_dataset_stream_buffer: 4     # per-dataset (multiplies memory)
    episode_queue_buffer: -1          # episodes (keep small; episodes can be large)

  # TFDS read (I/O) parallelism.
  tfds_read:
    source: auto           # gcs|local|auto
    local_root: /dss/dssfs04/pn69za/pn69za-dss-0004/datasets/open-x-embodiment
    cycle_length: 8
    block_length: 4
    decode_parallelism: -1           # -1 = tf.data.AUTOTUNE
    interleave_parallelism: -1       # -1 = tf.data.AUTOTUNE

  # tf.data pipeline parallelism.
  pipeline:
    episode_concurrency: -1
    transform_parallelism: -1
    interleave_parallelism: -1

  # Multi-dataset mixing behaviour.
  mixing:
    mix_block_length: 1              # 1 = per-sample mixing
    selector_run_length: 1
    parallelism_mode: full         # divide|sqrt|full
    strategy: sample                 # sample|choose|python
    per_dataset_private_threadpool_size: 16
