# @package _global_

# Sweep over learning rates for LAQ training
# Submits one job per parameter combination

defaults:
  - /model@model: laq
  - /data@data: laq_oxe
  - /training@training: laq_optimizer
  - /cluster@cluster: local_dev

# Sweep parameters - each combination becomes a separate job
# Uses custom 'sweep.params' key (compatible with submit_job.py)
sweep:
  params:
    training.optimizer.lr: 1e-4, 5e-5, 1e-5
    seed: 42, 123

experiment:
  name: laq_lr_sweep
  description: "Learning rate sweep for LAQ on OXE"

# Model
model:
  image_size: 256

# Data - use smaller subset for sweep
data:
  loader:
    batch_size: 32
  preprocess:
    return_metadata: true
  adapter:
    tf:
      train:
        episode_queue_shuffle_buffer: 1000
        intra_episode_sample_shuffle_buffer: 0
        global_stream_shuffle_buffer: 1000
      prefetch:
        final_stream_buffer: 4

# Training
training:
  epochs: 10
  max_steps: 20000
  scheduler:
    type: cosine
    warmup_steps: 1000
  validation:
    check_interval: 0.1
    limit_batches: 20

logging:
  use_wandb: true
