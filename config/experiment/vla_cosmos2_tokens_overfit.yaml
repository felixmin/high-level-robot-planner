# @package _global_

# Stage 2: diagnostic run to verify learning signal (overfit a single batch).
#
# Goal: quickly answer "does training work in principle?" without waiting for 30k steps.
# Expected behavior if everything is wired correctly:
# - val/label_code_token_mismatch_frac ~ 0
# - val/tf_code_token_accuracy quickly rises toward 1.0 on the repeated batch
# - val/tf_code_token_entropy drops (model becomes confident) without collapsing to a wrong token
#
# Uses the minimal TF adapter to avoid long shuffle-buffer warmup.

defaults:
  - /model@model: foundation_cosmos2_tokens_8_4
  - /data@data: laq_oxe_all_minimal
  - /training@training: vla_lightning_debug
  - /cluster@cluster: lrz_h100
  - optional /user_config: local

experiment:
  name: vla_cosmos2_tokens_overfit
  description: "Diagnostic: overfit one batch (Cosmos-Reason2 tokens, 8x4)"

submit:
  script: 4_train_foundation

data:
  loader:
    batch_size: 8
  adapter:
    tf:
      iterator:
        # Ensure a "true overfit-one-batch" run even with streaming tf.data.
        persistent: false
        cache_first_train_batch: true

training:
  max_steps: 300
  # `vla_lightning_debug` sets `max_epochs=1`, which would stop after a single
  # (overfit) batch. Set max_epochs high and let max_steps control termination.
  max_epochs: 1000
  overfit_batches: 1
  log_every_n_steps: 1
  train_teacher_forced_metrics_every_n_steps: 1
  train_visualization:
    every_n_steps: 50

  validation:
    # When `overfit_batches=1`, Lightning defines an epoch as a single batch,
    # so `val_check_interval` must be <= 1. Use epoch-based validation instead.
    check_interval: null
    check_val_every_n_epoch: 10
    limit_batches: 1

  # Keep artifacts small for debugging.
  checkpoint:
    save_top_k: 0
    save_last: false
    save_weights_only: true

logging:
  tags: ["debug", "foundation", "cosmos2", "tokens", "overfit"]
  log_model: false
