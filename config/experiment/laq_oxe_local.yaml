# @package _global_

# Minimal local OXE run (RAM-safe):
# - no shuffle buffers
# - no prefetching
# - no tf.data AUTOTUNE
# - tiny splits + tiny batch size

defaults:
  - /model@model: laq
  - /training@training: laq_optimizer
  - /cluster@cluster: local_dev

experiment:
  name: laq_oxe_local
  description: "Minimal local OXE run (no shuffle/prefetch/autotune)"

model:
  image_size: 256
  patch_size: 16
  dim: 256
  heads: 4
  dim_head: 32
  spatial_depth: 2
  temporal_depth: 2
  quant_dim: 16

data:
  # Small multi-dataset slice (streams from GCS, limited episodes)
  datasets:
    - name: language_table
      train_split: "train[:200]"
      val_split: "train[200:220]"
      offset: 10
      weight: 0.1
      size: 1000000
    - name: bridge
      train_split: "train[:200]"
      val_split: "train[200:220]"
      offset: 5
      size: 250000
    - name: rt1
      train_split: "train[:200]"
      val_split: "train[200:220]"
      offset: 3
      size: 250000
    - name: robonet
      train_split: "train[:200]"
      val_split: "train[200:220]"
      offset: 10
      size: 250000

  offset: 5
  image_size: 256
  batch_size: 24
  num_workers: 0

  # tf.data settings (tune in experiments)
  episode_shuffle_buffer: 0
  pair_shuffle_buffer: 0
  val_episode_shuffle_buffer: 0
  val_pair_shuffle_buffer: 0
  episode_prefetch_buffer: 0
  prefetch_buffer: 64
  num_parallel_episodes: 32
  num_parallel_calls: 32

  # Reduce output/overhead
  return_metadata: false
  persistent_iterator: true
  samples_per_episode: 0
  sampling_seed: 0

training:
  epochs: 1
  max_steps: 5
  scheduler:
    type: none
  profiler:
    enabled: true
    type: simple
    filename: fit-profile
  throughput:
    enabled: false
  dataset_usage_logger:
    enabled: false
  validation:
    check_interval: 1
    limit_batches: 0.0
    max_cached_samples: 0
    num_fixed_samples: 0
    num_random_samples: 0
    val_buckets: null
    strategies: null

logging:
  level: INFO
  use_wandb: false
