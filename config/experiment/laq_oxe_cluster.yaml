# @package _global_

# Minimal local OXE run (RAM-safe):
# - no shuffle buffers
# - no prefetching
# - no tf.data AUTOTUNE
# - tiny splits + tiny batch size

defaults:
  - /model@model: laq
  - /data@data: oxe_local_indexed
  - /training@training: laq_optimizer
  - /training/validation@training.validation: laq_cluster_rich
  - /cluster@cluster: mcml_h100
  - optional /user_config: local


experiment:
  name: laq_oxe_cluster
  description: "Cluster LAQ OXE run"

model:
  flow:
    model: raft_large    # "raft_small" or "raft_large"
    loss_weight: 1.0     # Weight for flow loss in total loss
    warmup_steps: 10000
    decoder_depth: 2
  codebook_replace_schedule: []

data:
  loader:
    batch_size: 64

training:
  profiler:
    enabled: true
    type: advanced
    filename: fit-profile

logging:
  level: INFO
  use_wandb: true
  project: hlrp
