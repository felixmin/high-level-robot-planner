# Base configuration for LAPA project
# This is the entry point for Hydra configuration composition

defaults:
  - _self_
  - experiment: laq_hf_local  # Default experiment (override with experiment=X)
  - override hydra/hydra_logging: disabled  # Disable Hydra's own logging
  - override hydra/job_logging: none        # We handle logging ourselves

# Global settings
experiment_name: ${experiment.name}
seed: 42
precision: "bf16-mixed"  # "32-true", "16-mixed", "bf16-mixed"

# Hydra configuration (default; submit_job overrides these to keep snapshots inside the run dir)
hydra:
  run:
    # Keep Hydra's `.hydra/` snapshots inside the same run directory as our unified logging.
    # If `logging.runs_dir` is set, use it; otherwise fall back to:
    #   <logging.root_dir or workspace>/runs/<timestamp>_<experiment.name>
    dir: ${oc.select:logging.runs_dir, ${oc.select:logging.root_dir,.}/runs/${now:%Y-%m-%d_%H-%M-%S}_${experiment.name}}
  sweep:
    dir: ${oc.select:logging.root_dir,.}/runs/sweeps/${now:%Y-%m-%d_%H-%M-%S}_${experiment.name}
    subdir: ${hydra.job.num}

# Logging configuration
logging:
  level: INFO                # Logging level (DEBUG, INFO, WARNING, ERROR)
  job_id: null               # Optional explicit run ID (used by submit_job local runs)
  root_dir: null             # Optional base directory for all run artifacts
  runs_dir: null             # Optional run directory (if null, scripts create a timestamped folder under <root_dir>/runs/)

  # WandB integration
  use_wandb: true            # Enable Weights & Biases logging
  project: hlrp              # WandB project name
  log_model: false           # Upload model checkpoints to WandB
  tags: []                   # WandB tags for run organization

  # Output structure (under logging.runs_dir):
  #   unified.log      - All logger.info() calls (timestamped)
  #   wandb/           - WandB files (includes print() capture)
  #   checkpoints/     - Model checkpoints
  #   .hydra/          - Hydra config snapshots (when hydra.run.dir is set to logging.runs_dir)

# Paths / caching
paths:
  # Base directory for large caches (HF weights, torch hub, TFDS cache, etc.).
  # If relative, resolved against `logging.root_dir` if set, else project root.
  cache_dir: cache

# Job submission defaults (used by scripts/submit_job.py)
submit:
  # Training entrypoint (without .py). Experiments can override this.
  script: 2_train_laq
  # If true, prints the generated sbatch script(s) but does not submit.
  dry_run: false
  # Where to persist pretrained model downloads (HF + torch/torchvision).
  cache_dir: cache

# Lightweight benchmarking knobs (used by scripts/bench_oxe_dataloader.py)
benchmark:
  warmup_steps: 20
  steps: 200
  # Optional: sleep after each batch fetch to simulate model compute time
  # and let tf.data prefetch overlap (0 disables).
  compute_sleep_s: 0.0
  tf_profile: false
  torch_profile: false
