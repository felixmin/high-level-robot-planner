# Base configuration for LAPA project
# This is the entry point for Hydra configuration composition

defaults:
  - _self_
  - experiment: laq_debug  # Default experiment (override with experiment=X)
  - override hydra/hydra_logging: disabled  # Disable Hydra's own logging
  - override hydra/job_logging: none        # We handle logging ourselves

# Global settings
experiment_name: ${experiment.name}
seed: 42
precision: "32-true"  # "32-true", "16-mixed", "bf16-mixed"

# Hydra configuration (routes .hydra config backups to runs folder)
hydra:
  run:
    dir: runs/output/hydra/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: runs/output/hydra/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}

# Logging configuration
logging:
  # Unified logging system (recommended)
  unified: true              # Enable unified logging to runs/ folder
  level: INFO                # Logging level (DEBUG, INFO, WARNING, ERROR)
  job_id: null               # Optional explicit run ID (used by submit_job local runs)
  root_dir: null             # Optional base directory for all run artifacts
  runs_dir: null             # Optional run-group directory (e.g., <root_dir>/runs/YYYY-MM-DD/HH-MM-SS)

  # WandB integration
  use_wandb: true            # Enable Weights & Biases logging
  project: hlrp              # WandB project name
  log_model: false           # Upload model checkpoints to WandB
  tags: []                   # WandB tags for run organization

  # Output structure:
  #   runs/logs/{job_id}.log                          - All logger.info() calls (timestamped)
  #   runs/output/{job_id}/wandb/                     - WandB files (includes print() capture)
  #   runs/output/{job_id}/checkpoints/               - Model checkpoints
  #   runs/output/hydra/YYYY-MM-DD/HH-MM-SS/.hydra/   - Hydra config backups

# Job submission defaults (used by scripts/submit_job.py)
submit:
  # Training entrypoint (without .py). Experiments can override this.
  script: 2_train_laq
  # If true, prints the generated sbatch script(s) but does not submit.
  dry_run: false
  # Where to persist pretrained model downloads (HF + torch/torchvision).
  cache_dir: cache
  # Where Slurm should write stdout/stderr (%j.out/.err).
  slurm_logs_dir: slurm
