# LAQ Model Configuration
# ViT-based VQ-VAE for latent action quantization (LAPA architecture)

name: laq_vit

# Model architecture (matches LAPA's LatentActionQuantization)
dim: 1024                # Transformer embedding dimension
quant_dim: 32           # Quantization dimension
codebook_size: 8        # Number of codebook entries
image_size: 256         # Input image size
patch_size: 32          # Patch size for ViT
spatial_depth: 8        # Number of spatial transformer layers
temporal_depth: 8       # Number of temporal transformer layers
dim_head: 64            # Attention head dimension
heads: 16               # Number of attention heads
code_seq_len: 4         # Length of quantized action sequence
channels: 3             # RGB channels
attn_dropout: 0.0       # Attention dropout
ff_dropout: 0.0         # Feed-forward dropout
use_aux_loss: true      # Whether to use auxiliary pixel loss

# Optional: Flow supervision config
# Enriches latent space with motion information via RAFT knowledge distillation
# To enable, set flow config in experiment (see laq_oxe_all_val_3.yaml)
# flow:
#   model: raft_small    # "raft_small" or "raft_large"
#   loss_weight: 0.1     # Weight for flow loss in total loss
#   decoder_depth: 8     # Transformer depth for flow decoder

