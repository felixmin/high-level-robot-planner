# LAQ Training Configuration
# Optimizer and scheduler settings for LAQ training

epochs: 100
max_steps: null  # If set, overrides epochs

optimizer:
  type: AdamW
  lr: 1.0e-4
  betas: [0.9, 0.999]
  weight_decay: 0.01
  eps: 1.0e-8

scheduler:
  type: none  # 'cosine', 'step', 'plateau', or 'none' to disable
  warmup_steps: 1000
  warmup_start_lr: 1.0e-6
  min_lr: 1.0e-6
  
  # For CosineAnnealingLR
  T_max: ${training.epochs}
  
  # For StepLR (if used)
  step_size: 30
  gamma: 0.1
  
  # For ReduceLROnPlateau (if used)
  mode: min
  factor: 0.5
  patience: 10

gradient:
  clip_val: 1.0
  clip_algorithm: norm  # 'norm' or 'value'

# Loss configuration
loss_weights:
  reconstruction: 1.0
  vq: 1.0  # Combined codebook + commitment

# Validation settings
validation:
  # How often to run validation (can be float for percentage of epoch, or int for steps)
  check_interval: 500

  # Limit validation batches to save time (0.1 = 10% of val set, or int for exact batches)
  # With 6300 val frame pairs, 0.1 = ~630 pairs = ~160 batches at batch_size 4
  # limit_batches: 1.0

  # Fixed pairs: diverse across datasets, tracked every validation
  num_fixed_samples: 8

  # Random pairs: different each time for diversity
  num_random_samples: 8

  # Maximum frame pairs to cache in RAM (prevents OOM on large val sets)
  max_cached_samples: 1024

  # --- Validation Buckets (for per-bucket visualization and analysis) ---
  # Define custom data subsets for separate visualization
  # Each bucket is a named filter - samples matching all conditions are grouped
  # If not specified, auto-bucketing by dataset_type is used
  # Supports operators: ["!=", value], [">", value], ["not_null", true]
  val_buckets:
    youtube:
      dataset_type: "youtube"
    bridge:
      dataset_type: "bridge"
    # Example: filter by environment
    # bridge_toykitchen1:
    #   dataset_type: "bridge"
    #   environment: "toykitchen1"
    # Example: filter for samples with language annotations
    # with_language:
    #   language: ["not_null", true]

  # --- Validation Strategies ---
  strategies:
    # Basic validation (always runs): loss + visualizations
    basic:
      enabled: true
      visualize_train: true
      visualize_val: true
      visualize_per_bucket: true  # Separate grids for each bucket
      samples_per_bucket: 4
      num_train_samples: 8  # Training samples to visualize

    # Latent transfer analysis: test if latent actions transfer between scenes
    latent_transfer:
      enabled: true
      every_n_validations: 2  # Run every 10th validation
      num_pairs: 256  # Number of pairs to test transfer on

    # Sequence examples: visualize frame pairs grouped by exact code sequence
    sequence_examples:
      enabled: true
      every_n_validations: 3
      top_k_sequences: 16  # Number of most frequent sequences to visualize
      examples_per_sequence: 4  # Frame pairs to show per sequence

# Checkpointing
checkpoint:
  monitor: val/loss
  mode: min
  save_top_k: 3
  save_last: true
  every_n_train_steps: 1000

# Profiling
profiler:
  enabled: true           # Enable Lightning SimpleProfiler
  type: simple             # 'simple', 'advanced', or 'pytorch'
  dirpath: ./profiles      # Where to save profile outputs
  filename: profile        # Profile filename

