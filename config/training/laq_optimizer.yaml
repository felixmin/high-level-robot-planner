# LAQ Training Configuration
# Optimizer and scheduler settings for LAQ training

epochs: 100
max_steps: null  # If set, overrides epochs

optimizer:
  type: AdamW
  lr: 1.0e-4
  betas: [0.9, 0.999]
  weight_decay: 0.01
  eps: 1.0e-8

scheduler:
  type: none  # 'cosine', 'step', 'plateau', or 'none' to disable
  warmup_steps: 1000
  warmup_start_lr: 1.0e-6
  min_lr: 1.0e-6
  
  # For CosineAnnealingLR
  T_max: ${training.epochs}
  
  # For StepLR (if used)
  step_size: 30
  gamma: 0.1
  
  # For ReduceLROnPlateau (if used)
  mode: min
  factor: 0.5
  patience: 10

gradient:
  clip_val: 1.0
  clip_algorithm: norm  # 'norm' or 'value'

# Loss configuration
loss_weights:
  reconstruction: 1.0
  vq: 1.0  # Combined codebook + commitment

# Validation settings
validation:
  # How often to run validation (can be float for percentage of epoch, or int for steps)
  check_interval: 500
  
  # Limit validation batches to save time (0.1 = 10% of val set, or int for exact batches)
  # With 6300 val samples, 0.1 = ~630 samples = ~160 batches at batch_size 4
  limit_batches: 0.1
  
  # Fixed samples: diverse across datasets, tracked every validation
  num_fixed_samples: 8
  
  # Random samples: different each time for diversity
  num_random_samples: 8
  
  # Maximum samples to cache in RAM (prevents OOM on large val sets)
  max_cached_samples: 256
  
  # --- Validation Strategies ---
  strategies:
    # Basic validation (always runs): loss + visualizations
    basic:
      enabled: true
      visualize_train: true
      visualize_val: true
      visualize_per_bucket: true  # Separate grids for YouTube/Bridge
      samples_per_bucket: 4
    
    # Latent transfer analysis: test if latent actions transfer between scenes
    latent_transfer:
      enabled: true
      every_n_validations: 10  # Run every 10th validation
      num_pairs: 256  # Number of pairs to test transfer on
    
    # Clustering analysis: analyze latent action distribution
    clustering:
      enabled: true
      every_n_validations: 20  # Run every 20th validation
      num_samples: 1000  # Samples to cluster
      num_clusters: 16  # Number of k-means clusters
      num_examples_per_cluster: 4  # Frame pairs to visualize per cluster

# Checkpointing
checkpoint:
  monitor: val/loss
  mode: min
  save_top_k: 3
  save_last: true
  every_n_epochs: 5

# Profiling
profiler:
  enabled: true           # Enable Lightning SimpleProfiler
  type: simple             # 'simple', 'advanced', or 'pytorch'
  dirpath: ./profiles      # Where to save profile outputs
  filename: profile        # Profile filename

