# LAQ Training Configuration
# Optimizer and scheduler settings for LAQ training

epochs: 100
max_steps: null  # If set, overrides epochs

# --- Logging / UI ---
# How often Lightning emits scalar logs (to wandb + any configured logger).
log_every_n_steps: 10

# Terminal progress bar (tqdm).
# NOTE: This is separate from `progress_logger` (which prints periodic lines for log files).
progress_bar:
  enabled: true
  refresh_rate: 10
  leave: false

# Lightning model summary (printed at startup).
model_summary:
  enabled: true

# Periodic text logging (useful in non-interactive logs, e.g. SLURM).
progress_logger:
  enabled: true
  log_every_n_steps: 10
  leave: false

# Model metrics: control frequency of expensive computations and logging.
metrics:
  # Log model-provided metrics dict every N steps.
  log_every_n_steps: 10
  # `torch.unique()` over code indices is expensive; compute it only every N steps.
  num_unique_codes_every_n_steps: 50

optimizer:
  type: AdamW
  lr: 1.0e-4
  betas: [0.9, 0.999]
  weight_decay: 0.01
  eps: 1.0e-8

scheduler:
  type: cosine  # 'cosine', 'step', 'plateau', or 'none' to disable
  warmup_steps: 1000
  warmup_start_lr: 1.0e-6
  min_lr: 1.0e-6
  
  # For cosine scheduling: the LR schedule is step-based.
  # Prefer setting `training.max_steps` for streaming / variable-length epochs.
  
  # For StepLR (if used)
  step_size: 30
  gamma: 0.1
  
  # For ReduceLROnPlateau (if used)
  mode: min
  factor: 0.5
  patience: 10

gradient:
  clip_val: 1.0
  clip_algorithm: norm  # 'norm' or 'value'

# Dataset usage logging: prints how much of each dataset was *actually consumed*
# between validations (uses `batch.dataset_name`).
dataset_usage_logger:
  enabled: true
  log_on_validation_end: true
  log_every_n_steps: 0  # 0 = disabled (validation-end summary only)
  key: dataset_name
  top_k: 12

# Throughput logging: logs perf/steps_per_sec and perf/samples_per_sec to wandb
throughput:
  enabled: true
  log_every_n_steps: 10

# Checkpointing
checkpoint:
  monitor: val/loss
  mode: min
  save_top_k: 3
  save_last: true
  every_n_train_steps: 2500

# Profiling
profiler:
  enabled: false           # Enable Lightning SimpleProfiler
  type: advanced             # 'simple', 'advanced', or 'pytorch'
  dirpath: ./profiles      # Where to save profile outputs
  filename: profile        # Profile filename
